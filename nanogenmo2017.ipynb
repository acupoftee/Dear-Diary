{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prereqs\n",
    "app_user_agent = \"user_agent\"\n",
    "app_client_id = \"client_id\"\n",
    "app_client_secret = \"client_secret\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get reddit instance\n",
    "import praw\n",
    "\n",
    "reddit = praw.Reddit(user_agent=app_user_agent,\n",
    "                     client_id=app_client_id,\n",
    "                     client_secret=app_client_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape text from r/dreams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hot_posts(subreddit, num):\n",
    "    \"\"\"Get top ranked posts\"\"\"\n",
    "    text = \"\"\n",
    "    for submission in reddit.subreddit(subreddit).hot(limit=num):\n",
    "        text += submission.selftext\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_random_post(subreddit):\n",
    "    submission = reddit.subreddit(subreddit).random()\n",
    "    return submission.selftext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_posts_to_file(subreddit, quantity, filename):\n",
    "    \"\"\"Build file for easier data processing\"\"\"\n",
    "    for x in range(0, quantity):\n",
    "        text = get_random_post(subreddit)\n",
    "        # append to file\n",
    "        with open(filename,'a') as f:\n",
    "            f.write(text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_posts_to_file('dreams', 5000, \"dreamstext\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Parsing and Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/bethydiakabana/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "# tokenize reddit text into sentences\n",
    "nltk.download('punkt')\n",
    "sent_detector = nltk.data.load('tokenizers/punkt/english.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove meta dream sentences to make it resemble a real journal\n",
    "substrings = ['dream', 'dreams', 'wake', 'woke', 'sleep', 'sleeping', 'nightmare']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_dream_from_sentences(text):\n",
    "    \"\"\"skips over words with substrings in them \n",
    "    when writing the final output\"\"\"\n",
    "    output = \"\"\n",
    "    for sentence in sent_detector.tokenize(text):\n",
    "        if any(substring in sentence for substring in substrings):\n",
    "            continue;\n",
    "        else:\n",
    "            output += \" \"\n",
    "            output += sentence\n",
    "    return output                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_output(filename):\n",
    "    with open(filename) as f:\n",
    "        text = f.read()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = get_output(\"dreamstext\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "My son is just shy of 5 months. My dog is 3 years old and I've had him since he was a puppy. This dream is haunting me today so I need to get it off my chest. It's kind of graphic.\n",
      "\n",
      "In my dream: My husband and I decided to take our son and dog to a themepark. We decided to take them on a rollercoaster. My husband sat in front of me while I had my son in an infant carrier (which I do use in real life) and I was holding onto my dog. \n"
     ]
    }
   ],
   "source": [
    "print(output_text[0:435])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate \"Dear Diary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import markovify\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_paragraph(clean_text):\n",
    "    \"\"\"Create generation model\"\"\"\n",
    "    text_model = markovify.Text(clean_text)\n",
    "    num_sentences = random.randint(5,25)\n",
    "    paragraph = \"\"\n",
    "    \n",
    "    # print varying number of randomly generated sentences\n",
    "    for i in range(num_sentences):\n",
    "        paragraph += \" \"\n",
    "        paragraph += text_model.make_sentence()\n",
    "    \n",
    "    return paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Anyway, we get placed in the corridor outside my window and run fast in a way out, every lift and slope leads to the war. Both bro and sis hugged me and I'm a teenager and me and I am suddenly in a room, or I might have gotten samples in the eye and then suddenly I felt so proud this man looked to be harmed to be harmed, say that this isn’t real. I was constantly yelling for doctors and nurses do their thing. It was one of the village on a streaming service called fullscreen. I decided that the entire plain a grey, darkened look. They’re always scary and intense, or at too high of a lack of oxygen. I run away and didn’t know what Doc Ock was doing in the throat, I felt my heart was pounding. So to start with it. So I was downstairs looking up at the flenser's underprotected legs. We were assigned to the ground grabs my left but early morning the next ring I get really drunk but it's more than average probably. Up there I meet Michael. They’re always scary and the next day. It was the same basement again and again she kept running as fast as possible and hoped it wouldnt lead me to take them on a laptop. I was late-night talking to some monster and I was so excited, I was watching some nonexistant Hitchcock film, and after it happened, and was about to go through its contents. This second wave got my wife walks in on us but this bright white light in the same death as her but could've been the same young boy who couldn’t even be in his hand. I guess in my movements. So much of my back, and i was 15 and have continued and still in a shock about what I just kept telling myself that your not gone, that all I have, because it's both and dementing.\n"
     ]
    }
   ],
   "source": [
    "# test randomly generated paragraph\n",
    "print(strip_dream_from_sentences(generate_paragraph(output_text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_start_date():\n",
    "    \"\"\"Get a random date in the past\"\"\"\n",
    "    past_date = random.randint(1000, 15000)\n",
    "    startdate = datetime.datetime.now() - datetime.timedelta(past_date)\n",
    "    return startdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_date(current_date):\n",
    "    \"\"\"Gets the next diary entry date by \n",
    "    progressing the diary every few days\"\"\"\n",
    "    added_days = random.randint(1, 5)\n",
    "    dry_date = current_date + datetime.timedelta(days=added_days)\n",
    "    return diary_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_novel(novel_name, novel_length):\n",
    "    start_date = get_start_date()\n",
    "    entry = strip_dream_from_sentences(generate_paragraph(output_text))\n",
    "    with open(novel_name, 'a') as f:\n",
    "        f.write(start_date.strftime(\"%B %d, %Y\") + '\\n')\n",
    "        f.write(entry + '\\n\\n')\n",
    "    for x in range(novel_length):\n",
    "        start_date = get_next_date(start_date)\n",
    "        entry = strip_dream_from_sentences(generate_paragraph(output_text))\n",
    "        with open(novel_name, 'a') as f:\n",
    "            f.write(start_date.strftime(\"%B %d, %Y\") + '\\n')\n",
    "            f.write(entry + '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_novel(\"dear_diary\", 365)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
